{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ad7233-8685-4e61-876f-efc3a57d3c43",
   "metadata": {},
   "source": [
    "# üìä YouTube Trend Analytics ‚Äî Script Generation Notebook\n",
    "\n",
    "This notebook prepares all essential Python scripts required for the **Daily YouTube Trend Automation System**, including:\n",
    "\n",
    "- Fetching supported country codes\n",
    "- Fetching YouTube category mappings\n",
    "- Utility function for converting video durations\n",
    "- Core script for fetching trending data for any region\n",
    "- Main automation script used in GitHub Actions\n",
    "\n",
    "All files generated from this notebook will be committed to the GitHub repository and used by the daily automation workflow.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d05e6d-cf8a-44bd-970d-6ed140c837c3",
   "metadata": {},
   "source": [
    "## üåç Fetch All Supported YouTube Countries\n",
    "\n",
    "YouTube supports trending videos for many regions.  \n",
    "This cell:\n",
    "- Loads the YouTube Data API key from the environment\n",
    "- Calls the `i18nRegions` endpoint\n",
    "- Extracts the list of region codes (IN, US, GB, BR, etc.)\n",
    "- Saves them into `countries.json`\n",
    "\n",
    "These region codes are used later for fetching trending videos for each country.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586a64ea-e448-4cd6-a2e1-0c20dd7038a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load environment variables (YOUTUBE_API_KEY)\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize YouTube Data API client\n",
    "API_KEY = os.getenv('YOUTUBE_API_KEY')\n",
    "YOUTUBE = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "def get_all_countries():\n",
    "    \"\"\"\n",
    "    Fetch all supported YouTube region codes (e.g., IN, US, BR, GB...).\n",
    "    Returns a list of country codes.\n",
    "    \"\"\"\n",
    "    request = YOUTUBE.i18nRegions().list(part=\"snippet\")\n",
    "    response = request.execute()\n",
    "\n",
    "    countries = []\n",
    "    for item in response[\"items\"]:\n",
    "        countries.append(item[\"id\"])\n",
    "    return countries\n",
    "\n",
    "# Fetch countries and save to JSON file\n",
    "countries = get_all_countries()\n",
    "with open(\"../countries.json\", \"w\") as f:\n",
    "    json.dump(countries, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0319e82d-0699-4d41-a046-a9baa4d8ee54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AE', 'BH', 'DZ', 'EG', 'IQ']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first 5 elements of the countries list\n",
    "countries[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534822d-c5b8-4c44-bafb-3c31a993c271",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Generate Category Mapping File\n",
    "\n",
    "This cell:\n",
    "- Fetches video categories for each country\n",
    "- Merges each one into a single dictionary\n",
    "- Saves the category ID ‚Üí category name mapping into `categories.json`\n",
    "\n",
    "This file is used by all future scripts to translate YouTube's category IDs to readable names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf5873f-c61c-4868-90d6-71f88e11b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_map():\n",
    "    \"\"\"\n",
    "    Fetch YouTube video categories for each country, merge them and return a mapping:\n",
    "        {category_id: category_name}\n",
    "    \"\"\"\n",
    "    categories = {} \n",
    "    for country in countries:\n",
    "        request = YOUTUBE.videoCategories().list(\n",
    "            part=\"snippet\",\n",
    "            regionCode=country\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        for item in response[\"items\"]:\n",
    "            if item[\"id\"] not in categories:\n",
    "                categories[item[\"id\"]] = item[\"snippet\"][\"title\"]\n",
    "    return categories\n",
    "\n",
    "# Fetch categories and save to JSON file\n",
    "categories = get_category_map()\n",
    "with open(\"../categories.json\", \"w\") as f:\n",
    "    json.dump(categories, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36789132-95b6-4968-92a4-86eb87188a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Film & Animation',\n",
       " '2': 'Autos & Vehicles',\n",
       " '10': 'Music',\n",
       " '15': 'Pets & Animals',\n",
       " '17': 'Sports',\n",
       " '18': 'Short Movies',\n",
       " '19': 'Travel & Events',\n",
       " '20': 'Gaming',\n",
       " '21': 'Videoblogging',\n",
       " '22': 'People & Blogs',\n",
       " '23': 'Comedy',\n",
       " '24': 'Entertainment',\n",
       " '25': 'News & Politics',\n",
       " '26': 'Howto & Style',\n",
       " '27': 'Education',\n",
       " '28': 'Science & Technology',\n",
       " '30': 'Movies',\n",
       " '31': 'Anime/Animation',\n",
       " '32': 'Action/Adventure',\n",
       " '33': 'Classics',\n",
       " '34': 'Comedy',\n",
       " '35': 'Documentary',\n",
       " '36': 'Drama',\n",
       " '37': 'Family',\n",
       " '38': 'Foreign',\n",
       " '39': 'Horror',\n",
       " '40': 'Sci-Fi/Fantasy',\n",
       " '41': 'Thriller',\n",
       " '42': 'Shorts',\n",
       " '43': 'Shows',\n",
       " '44': 'Trailers',\n",
       " '29': 'Nonprofits & Activism'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print categories dictionary\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138df15c-ff76-4c5d-8a42-ed56ab2a5444",
   "metadata": {},
   "source": [
    "## ‚è±Ô∏è Create Duration Conversion Utility\n",
    "\n",
    "This script (`convert_duration.py`) contains a helper function that converts\n",
    "ISO-8601 duration strings such as:\n",
    "\n",
    "- PT5M20S  \n",
    "- PT1H2M5S  \n",
    "- PT30S  \n",
    "\n",
    "into total seconds.\n",
    "\n",
    "This utility will be imported inside the trending fetch script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65a1352c-342e-4bd4-b96b-1875e4265fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/convert_duration.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/convert_duration.py\n",
    "import re\n",
    "\n",
    "def duration_to_seconds(duration):\n",
    "    \"\"\"\n",
    "    Convert ISO-8601 YouTube duration strings into total seconds.\n",
    "\n",
    "    Examples:\n",
    "        PT5M20S ‚Üí 320 seconds\n",
    "        PT1H2M5S ‚Üí 3725 seconds\n",
    "        PT30S ‚Üí 30 seconds\n",
    "\n",
    "    Parameters:\n",
    "        duration (str): ISO-8601 duration string\n",
    "\n",
    "    Returns:\n",
    "        int: Duration in seconds\n",
    "    \"\"\"\n",
    "    match = re.match(r'PT(?:(\\d+)H)?(?:(\\d+)M)?(?:(\\d+)S)?', duration)\n",
    "    if not match:\n",
    "        return 0\n",
    "    \n",
    "    hours = int(match.group(1)) if match.group(1) else 0\n",
    "    minutes = int(match.group(2)) if match.group(2) else 0\n",
    "    seconds = int(match.group(3)) if match.group(3) else 0\n",
    "    \n",
    "    return hours * 3600 + minutes * 60 + seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6935b5-c42c-4070-8f16-b2ca5883a0a2",
   "metadata": {},
   "source": [
    "## üì• Create Script to Fetch Trending Videos\n",
    "\n",
    "This script (`fetch_youtube_trend.py`) defines the function `get_trending_videos(region)`:\n",
    "\n",
    "- Calls the YouTube API for a specific region\n",
    "- Retrieves snippet, statistics, and content details\n",
    "- Maps video category IDs ‚Üí category names using `categories.json`\n",
    "- Converts video duration into seconds\n",
    "- Returns a clean pandas DataFrame\n",
    "\n",
    "This script is used by the main automation workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6117a014-91b6-44f9-ab74-4032be10e558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/fetch_youtube_trend.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/fetch_youtube_trend.py\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "from convert_duration import duration_to_seconds\n",
    "\n",
    "# Load API Key\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv('YOUTUBE_API_KEY')\n",
    "YOUTUBE = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "# Load category mapping\n",
    "with open(\"../categories.json\", \"r\") as f:\n",
    "    cat_map = json.load(f)\n",
    "\n",
    "def get_trending_videos(region):\n",
    "    \"\"\"\n",
    "    Fetch top 50 trending videos for a given region.\n",
    "\n",
    "    Parameters:\n",
    "        region (str): Country code (e.g., 'IN', 'US')\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned table of trending videos and metadata\n",
    "    \"\"\"\n",
    "    request = YOUTUBE.videos().list(\n",
    "        part=\"snippet,statistics,contentDetails\",\n",
    "        chart=\"mostPopular\",\n",
    "        regionCode=region,\n",
    "        maxResults=50\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    rows = []\n",
    "    for v in response.get(\"items\", []):\n",
    "        snippet = v[\"snippet\"]\n",
    "        stats = v.get(\"statistics\", {})\n",
    "        content = v.get(\"contentDetails\", {})\n",
    "        status = v.get(\"status\", {})\n",
    "        cid = snippet.get(\"categoryId\")\n",
    "\n",
    "        rows.append({\n",
    "            \"video_id\": v[\"id\"],\n",
    "            \"country\": region,\n",
    "            \"fetched_at\": datetime.now(timezone.utc).isoformat(),\n",
    "\n",
    "            # Snippet\n",
    "            \"published_at\": snippet.get(\"publishedAt\"),\n",
    "            \"title\": snippet.get(\"title\"),\n",
    "            \"localized_title\": snippet.get(\"localized\", {}).get(\"title\"),\n",
    "            \"channel_title\": snippet.get(\"channelTitle\"),\n",
    "            \"channel_id\": snippet.get(\"channelId\"),\n",
    "            \"category_id\": cid,\n",
    "            \"category_name\": cat_map.get(cid, \"Unknown\"),\n",
    "            \"tags\": \", \".join(snippet.get(\"tags\", [])),\n",
    "            \"tag_count\": len(snippet.get(\"tags\", [])),\n",
    "            \"thumbnail\": snippet.get(\"thumbnails\", {}).get(\"high\", {}).get(\"url\"),\n",
    "            \"default_language\": snippet.get(\"defaultLanguage\"),\n",
    "            \"audio_language\": snippet.get(\"defaultAudioLanguage\"),\n",
    "            \"is_live\": snippet.get(\"liveBroadcastContent\") == \"live\",\n",
    "\n",
    "            # Content details\n",
    "            \"duration\": duration_to_seconds(content.get(\"duration\")),\n",
    "            \"duration_raw\": content.get(\"duration\"),\n",
    "            \"definition\": content.get(\"definition\"),\n",
    "            \"caption_available\": content.get(\"caption\") == \"true\",\n",
    "            \"licensed_content\": content.get(\"licensedContent\", False),\n",
    "            \"embeddable\": status.get(\"embeddable\", False),\n",
    "            \"made_for_kids\": status.get(\"madeForKids\", False),\n",
    "\n",
    "            # Stats\n",
    "            \"views\": int(stats.get(\"viewCount\", 0)),\n",
    "            \"likes\": int(stats.get(\"likeCount\", 0)),\n",
    "            \"comments\": int(stats.get(\"commentCount\", 0)),\n",
    "        })\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "    df['fetched_at'] = pd.to_datetime(df['fetched_at'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b8aea-5283-4898-a295-92cf9d2871fc",
   "metadata": {},
   "source": [
    "## üöÄ Create Main Automation Script\n",
    "\n",
    "This script (`main.py`) orchestrates the full workflow:\n",
    "\n",
    "- Loads the list of countries from `countries.json`\n",
    "- Creates folder structure: `data/<year>/<country>/...`\n",
    "- Fetches trending videos for each region\n",
    "- Saves Country-level daily CSV (`trending_IN_2025-12-07.csv`)\n",
    "\n",
    "This script is the one executed daily by GitHub Actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3515979-fa74-4e8f-9132-b08a47464275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/main.py\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from fetch_youtube_trend import get_trending_videos\n",
    "\n",
    "# Load list of YouTube-supported countries\n",
    "with open(\"../countries.json\", 'r') as f:\n",
    "    countries = json.load(f)\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Main workflow:\n",
    "    - Create folder structure for the current year\n",
    "    - Fetch trending videos for every country\n",
    "    - Save country-level CSV files\n",
    "    \"\"\"\n",
    "    today = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "    year = today.split(\"-\")[0]\n",
    "    month = today.split(\"-\")[1]\n",
    "    BASE_DIR = os.path.abspath(\".\")\n",
    "    DATA_DIR = os.path.join(BASE_DIR, \"..\", \"data\")\n",
    "    \n",
    "    for country in countries:\n",
    "        print(f\"\\nFetching trending videos for {country}...\")\n",
    "\n",
    "        try:\n",
    "            df = get_trending_videos(country)\n",
    "\n",
    "            # Skip empty results\n",
    "            if df.empty:\n",
    "                print(f\"No trending data for {country}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Folder for the specific country and the date\n",
    "            COUNTRY_DIR = os.path.join(DATA_DIR, f\"country={country}\", f\"year={year}\", f\"month={month}\")\n",
    "            os.makedirs(COUNTRY_DIR, exist_ok=True)\n",
    "\n",
    "            # Save daily file\n",
    "            file_path = os.path.join(\n",
    "                COUNTRY_DIR,\n",
    "                f\"trending_{country}_{today}.csv\"\n",
    "            )\n",
    "\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"Saved ‚Üí {file_path}\")\n",
    "\n",
    "            time.sleep(0.3)  # Avoid API quota bursts\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {country}: {e}\")\n",
    "\n",
    "# Execute workflow when script is run\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
